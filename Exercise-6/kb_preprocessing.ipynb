{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:39:37.215122Z",
     "start_time": "2024-02-05T21:39:37.205403Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b40fd428643b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:39:40.412740Z",
     "start_time": "2024-02-05T21:39:37.216081Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from utils.data_processing import *\n",
    "from kb.weidmann_fd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d30fd2bf7b065e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:39:41.629769Z",
     "start_time": "2024-02-05T21:39:40.413639Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "dict_bottleneck = load_directory(bottleneck_files)\n",
    "dict_corridor = load_directory(corridor_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9966251402260",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Clean data and check for out of bounds values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3fda27a348caff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:39:41.653981Z",
     "start_time": "2024-02-05T21:39:41.630791Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uo-180-070\n",
      "X-min/max:  0.000 1.800\n",
      "Y-min/max:  0.000 7.970\n",
      "uo-180-095\n",
      "X-min/max:  0.000 1.800\n",
      "Y-min/max:  0.000 7.991\n",
      "uo-180-120\n",
      "X-min/max:  0.000 1.800\n",
      "Y-min/max:  0.000 7.979\n",
      "uo-180-180\n",
      "X-min/max:  0.002 1.800\n",
      "Y-min/max:  0.000 7.994\n"
     ]
    }
   ],
   "source": [
    "#  Clean bottleneck data\n",
    "for key in dict_bottleneck.keys():\n",
    "    dict_bottleneck[key] = remove_oob_bottleneck(transform(dict_bottleneck[key]))\n",
    "    #dict_bottleneck[key] = transform(dict_bottleneck[key])\n",
    "    print(key)\n",
    "    print('X-min/max: ', '%.3f' % np.min(dict_bottleneck[key][:,2]), '%.3f' % np.max(dict_bottleneck[key][:,2]))\n",
    "    print('Y-min/max: ', '%.3f' % np.min(dict_bottleneck[key][:,3]), '%.3f' % np.max(dict_bottleneck[key][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89e011049b70962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:39:41.711822Z",
     "start_time": "2024-02-05T21:39:41.654820Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ug-180-015\n",
      "X-min/max:  0.002 1.358\n",
      "Y-min/max:  0.002 5.399\n",
      "ug-180-030\n",
      "X-min/max:  0.000 1.428\n",
      "Y-min/max:  0.000 5.603\n",
      "ug-180-060\n",
      "X-min/max:  0.001 1.543\n",
      "Y-min/max:  0.000 5.958\n",
      "ug-180-085\n",
      "X-min/max:  0.000 1.679\n",
      "Y-min/max:  0.000 5.948\n",
      "ug-180-095\n",
      "X-min/max:  0.000 1.713\n",
      "Y-min/max:  0.000 6.000\n",
      "ug-180-110\n",
      "X-min/max:  0.000 1.652\n",
      "Y-min/max:  0.000 5.998\n",
      "ug-180-140\n",
      "X-min/max:  0.000 1.780\n",
      "Y-min/max:  0.000 6.000\n",
      "ug-180-230\n",
      "X-min/max:  0.000 1.691\n",
      "Y-min/max:  0.000 6.000\n"
     ]
    }
   ],
   "source": [
    "# Clean corridor data\n",
    "for key in dict_corridor.keys():\n",
    "    dict_corridor[key] = remove_oob_corridor(transform(dict_corridor[key]))\n",
    "    #dict_corridor[key] = transform(dict_corridor[key])\n",
    "    print(key)\n",
    "    print('X-min/max: ', '%.3f' % np.min(dict_corridor[key][:,2]), '%.3f' % np.max(dict_corridor[key][:,2]))\n",
    "    print('Y-min/max: ', '%.3f' % np.min(dict_corridor[key][:,3]), '%.3f' % np.max(dict_corridor[key][:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798030f3a8969a34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calculate mean spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4046ebef2141f149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:40:24.766185Z",
     "start_time": "2024-02-05T21:39:41.708136Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uo-180-070\n",
      "min: 0.0 | max: 4.039246305790373\n",
      "mean: 0.8210620485801154 | std: 0.23024290848500958\n",
      "uo-180-095\n",
      "min: 0.0 | max: 3.0873367859314595\n",
      "mean: 0.8583133814310978 | std: 0.2351525482745232\n",
      "uo-180-120\n",
      "min: 0.0 | max: 4.100546343117091\n",
      "mean: 0.9186395118133803 | std: 0.23949239797322683\n",
      "uo-180-180\n",
      "min: 0.0 | max: 3.1421798783198236\n",
      "mean: 1.1015509274169004 | std: 0.31076718487184063\n",
      "overall mean: 0.9098044038700988 | std: 0.2715085320382021\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean spacing for bottleneck\n",
    "mean_spacing_bottleneck = np.array([])\n",
    "for key in dict_bottleneck.keys():\n",
    "    dict_bottleneck[key] = np.c_[dict_bottleneck[key], calculate_spacing(dict_bottleneck[key], 10)]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_bottleneck[key][:, 4])} | max: {np.max(dict_bottleneck[key][:, 4])}')\n",
    "    print(f'mean: {np.mean(dict_bottleneck[key][:, 4])} | std: {np.std(dict_bottleneck[key][:, 4])}')\n",
    "    mean_spacing_bottleneck = np.concatenate((mean_spacing_bottleneck, dict_bottleneck[key][:, 4]))\n",
    "print(f'overall mean: {np.mean(mean_spacing_bottleneck)} | std: {np.std(mean_spacing_bottleneck)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30b38cb88c6c310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:41.974225Z",
     "start_time": "2024-02-05T21:40:24.767053Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ug-180-015\n",
      "min: 0.0 | max: 2.47234436773148\n",
      "mean: 0.9518766305487631 | std: 0.46647066441046214\n",
      "ug-180-030\n",
      "min: 0.0 | max: 1.7489828822006495\n",
      "mean: 0.8744453113231336 | std: 0.23966108486194923\n",
      "ug-180-060\n",
      "min: 0.0 | max: 3.0726232686831985\n",
      "mean: 1.1751082157404538 | std: 0.46379771023078276\n",
      "ug-180-085\n",
      "min: 0.0 | max: 2.8706164183829364\n",
      "mean: 1.2353732149738703 | std: 0.3950160697636674\n",
      "ug-180-095\n",
      "min: 0.0 | max: 2.9189992105584492\n",
      "mean: 0.9596228316603843 | std: 0.3042850645303414\n",
      "ug-180-110\n",
      "min: 0.0 | max: 3.0267262626888147\n",
      "mean: 1.0184619438595854 | std: 0.329261344710946\n",
      "ug-180-140\n",
      "min: 0.0 | max: 3.026777220150798\n",
      "mean: 0.8243108026916338 | std: 0.2381153431413491\n",
      "ug-180-230\n",
      "min: 0.0 | max: 2.8961248683072043\n",
      "mean: 0.7630141394233086 | std: 0.2622646643068203\n",
      "overall mean: 0.904831694503841 | std: 0.32991957673296785\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean spacing for corridor\n",
    "mean_spacing_corridor = np.array([])\n",
    "for key in dict_corridor.keys():\n",
    "    dict_corridor[key] = np.c_[dict_corridor[key], calculate_spacing(dict_corridor[key], 10)]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_corridor[key][:, 4])} | max: {np.max(dict_corridor[key][:, 4])}')\n",
    "    print(f'mean: {np.mean(dict_corridor[key][:, 4])} | std: {np.std(dict_corridor[key][:, 4])}')\n",
    "    mean_spacing_corridor = np.concatenate((mean_spacing_corridor, dict_corridor[key][:, 4]))\n",
    "print(f'overall mean: {np.mean(mean_spacing_corridor)} | std: {np.std(mean_spacing_corridor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c86dae1c8bd8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calculate speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274e8b3982e5e176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:42.245282Z",
     "start_time": "2024-02-05T21:43:41.975615Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Old Speed\n",
      "uo-180-070\n",
      "min: 0.0 | max: 47.531092611047775\n",
      "mean: 0.4913586642657793 | std: 0.6091361457186338\n",
      "uo-180-095\n",
      "min: 0.0 | max: 51.865458756363736\n",
      "mean: 0.5111124631386309 | std: 0.7494861845120463\n",
      "uo-180-120\n",
      "min: 0.0 | max: 52.83639018101065\n",
      "mean: 0.6817895603301023 | std: 0.9477503546642424\n",
      "uo-180-180\n",
      "min: 0.0 | max: 13.861885730996345\n",
      "mean: 0.908229136974907 | std: 0.2762170885231334\n",
      "overall mean: 0.6230243850949965 | std: 0.715324772568433\n",
      "----------New Speed\n",
      "uo-180-070\n",
      "min: 0.0018129868201396337 | max: 3.5591741597314397\n",
      "mean: 0.42713420801863744 | std: 0.3104917648331764\n",
      "uo-180-095\n",
      "min: 0.02419429593933241 | max: 3.4903862258289196\n",
      "mean: 0.44426178348660694 | std: 0.2825889766334684\n",
      "uo-180-120\n",
      "min: 0.07764000675553803 | max: 3.8306492659078053\n",
      "mean: 0.6066070014169175 | std: 0.31030614757250297\n",
      "uo-180-180\n",
      "min: 0.31373674502837573 | max: 1.9241044681877335\n",
      "mean: 0.835814026128468 | std: 0.1994592063393343\n",
      "overall mean: 0.5539414515923085 | std: 0.323737251187462\n"
     ]
    }
   ],
   "source": [
    "# Calculate speeds for bottleneck\n",
    "print(\"----------Old Speed\")\n",
    "mean_speed_bottleneck_old = np.array([])\n",
    "dict_bottleneck_old = {}\n",
    "for key in dict_bottleneck.keys():\n",
    "    dict_bottleneck_old[key] = calculate_speeds(dict_bottleneck[key], old=True)\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_bottleneck_old[key])} | max: {np.max(dict_bottleneck_old[key])}')\n",
    "    print(f'mean: {np.mean(dict_bottleneck_old[key])} | std: {np.std(dict_bottleneck_old[key])}')\n",
    "    mean_speed_bottleneck_old = np.concatenate((mean_speed_bottleneck_old, dict_bottleneck_old[key]))\n",
    "print(f'overall mean: {np.mean(mean_speed_bottleneck_old)} | std: {np.std(mean_speed_bottleneck_old)}')\n",
    "\n",
    "print(\"----------New Speed\")\n",
    "mean_speed_bottleneck = np.array([])\n",
    "for key in dict_bottleneck.keys():\n",
    "    dict_bottleneck[key] = np.c_[dict_bottleneck[key], calculate_speeds(dict_bottleneck[key], old=False)]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_bottleneck[key][:, 5])} | max: {np.max(dict_bottleneck[key][:, 5])}')\n",
    "    print(f'mean: {np.mean(dict_bottleneck[key][:, 5])} | std: {np.std(dict_bottleneck[key][:, 5])}')\n",
    "    mean_speed_bottleneck = np.concatenate((mean_speed_bottleneck, dict_bottleneck[key][:, 5]))\n",
    "print(f'overall mean: {np.mean(mean_speed_bottleneck)} | std: {np.std(mean_speed_bottleneck)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ffc1dec19a7351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:42.986444Z",
     "start_time": "2024-02-05T21:43:42.246595Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Old Speed\n",
      "ug-180-015\n",
      "min: 0.0 | max: 1.5433064630150388\n",
      "mean: 1.090231028618292 | std: 0.22888594644813282\n",
      "ug-180-030\n",
      "min: 0.0 | max: 1.5478034619627998\n",
      "mean: 0.9835197302649191 | std: 0.24588141633531202\n",
      "ug-180-060\n",
      "min: 0.0 | max: 3.357778493806322\n",
      "mean: 0.7278526686712734 | std: 0.1956824147986169\n",
      "ug-180-085\n",
      "min: 0.0 | max: 2.3145620916606426\n",
      "mean: 0.538786603830015 | std: 0.2200241286196136\n",
      "ug-180-095\n",
      "min: 0.0 | max: 6.005981021621622\n",
      "mean: 0.5053715277688853 | std: 0.3473253146386251\n",
      "ug-180-110\n",
      "min: 0.0 | max: 5.463355290458045\n",
      "mean: 0.3290706498704181 | std: 0.2482423977212581\n",
      "ug-180-140\n",
      "min: 0.0 | max: 6.111322483714923\n",
      "mean: 0.28965849652942083 | std: 0.2890672920523519\n",
      "ug-180-230\n",
      "min: 0.0 | max: 12.411732268363396\n",
      "mean: 0.23431000098300173 | std: 0.2816975032014103\n",
      "overall mean: 0.374938843488874 | std: 0.3319917482098039\n",
      "----------New Speed\n",
      "ug-180-015\n",
      "min: 0.0016859801303691134 | max: 1.2831350763364708\n",
      "mean: 1.0296255217435162 | std: 0.16299496007802353\n",
      "ug-180-030\n",
      "min: 0.0008814193099769261 | max: 1.271660834914027\n",
      "mean: 0.9261373448179069 | std: 0.19224051859658667\n",
      "ug-180-060\n",
      "min: 0.0013870832707514632 | max: 0.9867070260523128\n",
      "mean: 0.6725083523021311 | std: 0.1510334095223265\n",
      "ug-180-085\n",
      "min: 0.00029013962156187887 | max: 0.9989874404115396\n",
      "mean: 0.485097186255476 | std: 0.1872486300555676\n",
      "ug-180-095\n",
      "min: 0.0003645490364820173 | max: 1.581450109514682\n",
      "mean: 0.4479691541813658 | std: 0.3218590273835614\n",
      "ug-180-110\n",
      "min: 0.0 | max: 0.9857655536581912\n",
      "mean: 0.2815902745709644 | std: 0.21235127146526375\n",
      "ug-180-140\n",
      "min: 0.0 | max: 1.5917853614416733\n",
      "mean: 0.2429122173321591 | std: 0.2628453288448497\n",
      "ug-180-230\n",
      "min: 0.0 | max: 1.2604342729072426\n",
      "mean: 0.1934200271420621 | std: 0.25336125356936107\n",
      "overall mean: 0.3265894262558153 | std: 0.30474312121844405\n"
     ]
    }
   ],
   "source": [
    "# Calculate speeds for corridor\n",
    "print(\"----------Old Speed\")\n",
    "mean_speed_corridor_old = np.array([])\n",
    "dict_corridor_old = {}\n",
    "for key in dict_corridor.keys():\n",
    "    dict_corridor_old[key] = calculate_speeds(dict_corridor[key], old=True)\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_corridor_old[key])} | max: {np.max(dict_corridor_old[key])}')\n",
    "    print(f'mean: {np.mean(dict_corridor_old[key])} | std: {np.std(dict_corridor_old[key])}')\n",
    "    mean_speed_corridor_old = np.concatenate((mean_speed_corridor_old, dict_corridor_old[key]))\n",
    "print(f'overall mean: {np.mean(mean_speed_corridor_old)} | std: {np.std(mean_speed_corridor_old)}')\n",
    "\n",
    "print(\"----------New Speed\")\n",
    "mean_speed_corridor = np.array([])\n",
    "for key in dict_corridor.keys():\n",
    "    dict_corridor[key] = np.c_[dict_corridor[key], calculate_speeds(dict_corridor[key], old=False)]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(dict_corridor[key][:, 5])} | max: {np.max(dict_corridor[key][:, 5])}')\n",
    "    print(f'mean: {np.mean(dict_corridor[key][:, 5])} | std: {np.std(dict_corridor[key][:, 5])}')\n",
    "    mean_speed_corridor = np.concatenate((mean_speed_corridor, dict_corridor[key][:, 5]))\n",
    "print(f'overall mean: {np.mean(mean_speed_corridor)} | std: {np.std(mean_speed_corridor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e149c996961727d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calculate densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24fcfcafd936cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:43.153216Z",
     "start_time": "2024-02-05T21:43:42.988284Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uo-180-070\n",
      "min: 0.06944444444444445 | max: 3.194444444444444\n",
      "mean: 2.1390778533635677 | std: 0.9053391153797452\n",
      "uo-180-095\n",
      "min: 0.06944444444444445 | max: 3.333333333333333\n",
      "mean: 2.056978798586572 | std: 0.8829985053770022\n",
      "uo-180-120\n",
      "min: 0.06944444444444445 | max: 2.8472222222222223\n",
      "mean: 1.8972434626640235 | std: 0.7205976476812094\n",
      "uo-180-180\n",
      "min: 0.06944444444444445 | max: 2.2222222222222223\n",
      "mean: 1.4828279062059821 | std: 0.4948405768623155\n",
      "overall mean: 1.8953867537628952 | std: 0.8126356037406586\n"
     ]
    }
   ],
   "source": [
    "# Calculate densities for bottleneck\n",
    "mean_density_bottleneck = np.array([])\n",
    "for key in dict_bottleneck.keys():\n",
    "    d_vec, den = calculate_density(dict_bottleneck[key], bottleneck=True)\n",
    "    dict_bottleneck[key] = np.c_[dict_bottleneck[key], d_vec]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(den)} | max: {np.max(den)}')\n",
    "    print(f'mean: {np.mean(den)} | std: {np.std(den)}')\n",
    "    mean_density_bottleneck = np.concatenate((mean_density_bottleneck, den))\n",
    "print(f'overall mean: {np.mean(mean_density_bottleneck)} | std: {np.std(mean_density_bottleneck)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb69fffbae2d0a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:44.108173Z",
     "start_time": "2024-02-05T21:43:43.153874Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ug-180-015\n",
      "min: 0.09259259259259259 | max: 0.4629629629629629\n",
      "mean: 0.23090917853442247| std: 0.09334830051236086\n",
      "ug-180-030\n",
      "min: 0.09259259259259259 | max: 0.6481481481481481\n",
      "mean: 0.4352886405959031| std: 0.11719493585586162\n",
      "ug-180-060\n",
      "min: 0.09259259259259259 | max: 1.574074074074074\n",
      "mean: 1.04720665037612| std: 0.23369990776576016\n",
      "ug-180-085\n",
      "min: 0.09259259259259259 | max: 1.759259259259259\n",
      "mean: 1.2016876908012208| std: 0.2767846804896936\n",
      "ug-180-095\n",
      "min: 0.09259259259259259 | max: 2.7777777777777777\n",
      "mean: 1.6593613815836037| std: 0.6874467517678862\n",
      "ug-180-110\n",
      "min: 0.09259259259259259 | max: 2.685185185185185\n",
      "mean: 1.6117553876889976| std: 0.5136968741753009\n",
      "ug-180-140\n",
      "min: 0.09259259259259259 | max: 3.2407407407407405\n",
      "mean: 2.1176283246333583| std: 0.7220513824584159\n",
      "ug-180-230\n",
      "min: 0.09259259259259259 | max: 4.351851851851851\n",
      "mean: 2.7729148395511483| std: 1.0464443631295097\n",
      "overall mean: 1.655899985047483 | std: 0.9755723782315162\n"
     ]
    }
   ],
   "source": [
    "# Calculate densities for corridor\n",
    "mean_density_corridor = np.array([])\n",
    "for key in dict_corridor.keys():\n",
    "    d_vec, den = calculate_density(dict_corridor[key], bottleneck=False)\n",
    "    dict_corridor[key] = np.c_[dict_corridor[key], d_vec]\n",
    "    print(key)\n",
    "    print(f'min: {np.min(den)} | max: {np.max(den)}')\n",
    "    print(f'mean: {np.mean(den)}| std: {np.std(den)}')\n",
    "    mean_density_corridor = np.concatenate((mean_density_corridor, den))\n",
    "print(f'overall mean: {np.mean(mean_density_corridor)} | std: {np.std(mean_density_corridor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f8cf27398f4d1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Write datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd21b581c95e2dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T21:43:44.928929Z",
     "start_time": "2024-02-05T21:43:44.108785Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean data path\n",
    "bottleneck_clean = Path(\"Bottleneck_Clean\")\n",
    "corridor_clean = Path(\"Corridor_Clean\")\n",
    "\n",
    "# Write datasets to clean data directory\n",
    "for key in dict_bottleneck.keys():\n",
    "    write_dataset(dict_bottleneck[key], str(bottleneck_clean) + '/'+ str(key))\n",
    "for key in dict_corridor.keys():\n",
    "    write_dataset(dict_corridor[key], str(corridor_clean) + '/' +  str(key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
